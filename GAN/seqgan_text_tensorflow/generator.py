__author__ = 'fanfan'
from GAN.seqgan_text_tensorflow import setting
import tensorflow as tf
from tensorflow.contrib import rnn
class Generator(object):
    def __init__(self):
        self.embedding_dim  = setting.embedding_dim
        self.vocab_size = setting.vocab_size
        self.batch_size = setting.batch_size
        self.hidden_dim = setting.hidden_dim
        self.seq_length = setting.seq_length
        self.start_token = tf.constant([setting.start_token] * self.batch_size,dtype=tf.int32)
        self.learning_rate = tf.Variable(float(setting.learning_rate),trainable=False)
        self.reward_gamma = setting.reward_gamma
        self.temperature = setting.temperature
        self.grad_clip = setting.grad_clip

        self.expected_reward = tf.Variable(tf.zeros([self.seq_length]))

        # sequence of tokens generated by generator
        self.x = tf.placeholder(tf.int32,shape=[self.batch_size,self.seq_length])
        # get from rollout policy and discriminator
        self.reward = tf.placeholder(tf.float32,shape=[self.batch_size,self.seq_length])

        with tf.variable_scope('generator'):
            self.g_embeddings = tf.get_variable(name='embedding',shape=[self.vocab_size,self.embedding_dim])
            self.x_embedding = tf.nn.embedding_lookup(self.g_embeddings,self.x)

            cell = rnn.LSTMCell(self.hidden_dim)

            (outputs, state)  = tf.nn.dynamic_rnn(cell,inputs=self.x_embedding,sequence_length=self.seq_length)

            with tf.variable_scope("sorftmax_layer"):
                self.Wo = tf.get_variable(name='weight',shape=[self.hidden_dim,self.vocab_size],initializer=tf.truncated_normal_initializer)
                self.bo = tf.get_variable(name='bias',shape=[self.vocab_size],initializer=tf.truncated_normal_initializer)

                logits = tf.matmul(outputs,self.Wo) + self.bo
